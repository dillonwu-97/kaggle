{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting who got iced in the Titanic\n",
    "This is a machine learning project that is meant to solidify an understanding of important algorithms used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "# Preprocessing Tools\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "\n",
    "\n",
    "# Algorithms / learning models to test\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "train_orig = pd.read_csv(\"/Users/Kvothe/Desktop/ml_projects/titanic/titanic/train.csv\")\n",
    "test = pd.read_csv(\"/Users/Kvothe/Desktop/ml_projects/titanic/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like to keep a copy of the original data so I make changes on train\n",
    "train = train_orig.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Missing Data and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training data for the y\n",
    "train_y = train['Survived']\n",
    "train_y\n",
    "train.drop(['Survived'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at which columns have null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Replace null values for some columns\n",
    "    data.fillna(value={'Age':data.Age.median(), 'Embarked':data.Embarked.mode()[0], 'Fare':data.Fare.median()}, inplace=True)\n",
    "    # Engineering some features\n",
    "    data['fam_size'] = data['SibSp'] + data['Parch']\n",
    "    data['isalone'] = 0\n",
    "    data['isalone'].loc[data['fam_size'] < 1] = 1\n",
    "    data['farebins'] = pd.qcut(data['Fare'], 4)\n",
    "    data['agebins'] = pd.qcut(data['Age'], 4)\n",
    "    # One hot encoding some of the columns\n",
    "    dummy = pd.concat([pd.get_dummies(data[s]) for s in ['Sex', 'Embarked', 'farebins', 'agebins']], axis=1, sort=False)\n",
    "    data = pd.concat([data, dummy], axis=1, sort=False)\n",
    "    # Isolating columns with categorical variables and dropping them\n",
    "    cols = data.columns\n",
    "    num_cols = data._get_numeric_data().columns\n",
    "    cat_cols = list(set(cols)-set(num_cols))\n",
    "    data.drop(cat_cols,axis=1,inplace=True)\n",
    "    data.columns = data.columns.astype(str).str.replace(\"\\]\", \"_\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying preprocessing to the submission dataset\n",
    "train = preprocess(train)\n",
    "submission = preprocess(test)\n",
    "print(train.shape)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cabin']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Median age for now, this can be replaced with something else\n",
    "#Replace Embarked with mode value\n",
    "train.fillna(value={'Age':train.Age.median(), 'Embarked':train.Embarked.mode()[0]}, inplace=True)\n",
    "train.columns[train.isna().any()].tolist() # <-- shows all null columns\n",
    "#train.columns[train.isnull().any()] # <-- shows all nulls columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# The goal is to engineer four features: familysize, isalone, farebins, agebins\n",
    "train['fam_size'] = train['SibSp'] + train['Parch']\n",
    "train['isalone'] = 0\n",
    "train['isalone'].loc[train['fam_size'] < 1] = 1\n",
    "train['farebins'] = pd.qcut(train['Fare'], 4)\n",
    "train['agebins'] = pd.qcut(train['Age'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the categorical columns\n",
    "cols = train.columns\n",
    "\n",
    "num_cols = train._get_numeric_data().columns\n",
    "cat_cols = list(set(cols)-set(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding of sex, ticket, embarked\n",
    "# One hot encoding might be easier just using pandas instead of sklearn \n",
    "dummy = pd.concat([pd.get_dummies(train[s]) for s in ['Sex','Ticket', 'Embarked', 'farebins', 'agebins']], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding \n",
    "# train_temp=train.copy()\n",
    "# dummy = pd.get_dummies(train['Ticket'])\n",
    "# Thought about filling in Cabin with random values of most visited cabin \n",
    "#random.choice(random.choice(train_temp.Cabin.mode()).split())\n",
    "train = pd.concat([train, dummy], axis=1, sort=False)\n",
    "train.drop(cat_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to make sure all null columns are gone\n",
    "train.columns[train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Columns: 703 entries, PassengerId to (35.0, 80.0]\n",
      "dtypes: float64(2), int64(7), uint8(694)\n",
      "memory usage: 666.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>fam_size</th>\n",
       "      <th>isalone</th>\n",
       "      <th>female</th>\n",
       "      <th>...</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>(-0.001, 7.91]</th>\n",
       "      <th>(7.91, 14.454]</th>\n",
       "      <th>(14.454, 31.0]</th>\n",
       "      <th>(31.0, 512.329]</th>\n",
       "      <th>(0.419, 22.0]</th>\n",
       "      <th>(22.0, 28.0]</th>\n",
       "      <th>(28.0, 35.0]</th>\n",
       "      <th>(35.0, 80.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>547</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>812</td>\n",
       "      <td>813</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>387</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 703 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  fam_size  \\\n",
       "546          547         1       2  19.0      1      0  26.0000         1   \n",
       "636          637         0       3  32.0      0      0   7.9250         0   \n",
       "812          813         0       2  35.0      0      0  10.5000         0   \n",
       "590          591         0       3  35.0      0      0   7.1250         0   \n",
       "289          290         1       3  22.0      0      0   7.7500         0   \n",
       "386          387         0       3   1.0      5      2  46.9000         7   \n",
       "294          295         0       3  24.0      0      0   7.8958         0   \n",
       "101          102         0       3  28.0      0      0   7.8958         0   \n",
       "315          316         1       3  26.0      0      0   7.8542         0   \n",
       "170          171         0       1  61.0      0      0  33.5000         0   \n",
       "\n",
       "     isalone  female  ...  Q  S  (-0.001, 7.91]  (7.91, 14.454]  \\\n",
       "546        0       1  ...  0  1               0               0   \n",
       "636        1       0  ...  0  1               0               1   \n",
       "812        1       0  ...  0  1               0               1   \n",
       "590        1       0  ...  0  1               1               0   \n",
       "289        1       1  ...  1  0               1               0   \n",
       "386        0       0  ...  0  1               0               0   \n",
       "294        1       0  ...  0  1               1               0   \n",
       "101        1       0  ...  0  1               1               0   \n",
       "315        1       1  ...  0  1               1               0   \n",
       "170        1       0  ...  0  1               0               0   \n",
       "\n",
       "     (14.454, 31.0]  (31.0, 512.329]  (0.419, 22.0]  (22.0, 28.0]  \\\n",
       "546               1                0              1             0   \n",
       "636               0                0              0             0   \n",
       "812               0                0              0             0   \n",
       "590               0                0              0             0   \n",
       "289               0                0              1             0   \n",
       "386               0                1              1             0   \n",
       "294               0                0              0             1   \n",
       "101               0                0              0             1   \n",
       "315               0                0              0             1   \n",
       "170               0                1              0             0   \n",
       "\n",
       "     (28.0, 35.0]  (35.0, 80.0]  \n",
       "546             0             0  \n",
       "636             1             0  \n",
       "812             1             0  \n",
       "590             1             0  \n",
       "289             0             0  \n",
       "386             0             0  \n",
       "294             0             0  \n",
       "101             0             0  \n",
       "315             0             0  \n",
       "170             0             1  \n",
       "\n",
       "[10 rows x 703 columns]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of information\n",
    "train.info()\n",
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String replacement for xgboost\n",
    "train.columns = train.columns.astype(str).str.replace(\"\\]\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Using Various ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the most basic algorithm is KNN so we'll try it on knn with some tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split, .75\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, train_y, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6322869955156951"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=45)\n",
    "knn.fit(x_train, y_train)\n",
    "train_predict = knn.predict(x_test)\n",
    "accuracy_score(y_test, train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using kfold cv to tune hyperparameters\n",
    "# Testig for just one case\n",
    "#scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')\n",
    "#scores.mean()\n",
    "k_range = range(2, 50)\n",
    "k_scores = []\n",
    "for i in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    ks = cross_val_score(knn, x_train, y_train, cv = 5, scoring='accuracy')\n",
    "    k_scores.append(ks.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "0.676658063068118\n"
     ]
    }
   ],
   "source": [
    "# Print optimal k and the index \n",
    "print(k_scores.index(max(k_scores)))\n",
    "print(max(k_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of machine learning algorithms to go through\n",
    "MLA = [    \n",
    "    XGBClassifier(),\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseShuffleSplit.split at 0x128eb85d0>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using shufflesplit to split the data\n",
    "ssplit = ShuffleSplit(train_size=.75, test_size=.25)\n",
    "ssplit.split(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Starting XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) -----\n",
      "-----Starting AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None) -----\n",
      "-----Starting BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False) -----\n",
      "-----Starting ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False) -----\n",
      "-----Starting GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) -----\n",
      "-----Starting RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) -----\n",
      "-----Starting GaussianProcessClassifier(copy_X_train=True, kernel=None, max_iter_predict=100,\n",
      "                          multi_class='one_vs_rest', n_jobs=None,\n",
      "                          n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
      "                          random_state=None, warm_start=False) -----\n",
      "-----Starting LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
      "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
      "                     max_iter=100, multi_class='warn', n_jobs=None,\n",
      "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0) -----\n",
      "-----Starting PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False) -----\n",
      "-----Starting RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]), class_weight=None, cv=None,\n",
      "                  fit_intercept=True, normalize=False, scoring=None,\n",
      "                  store_cv_values=False) -----\n",
      "-----Starting SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) -----\n",
      "-----Starting Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False) -----\n",
      "-----Starting BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) -----\n",
      "-----Starting GaussianNB(priors=None, var_smoothing=1e-09) -----\n",
      "-----Starting KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform') -----\n",
      "-----Starting SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False) -----\n",
      "-----Starting NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "      decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "      kernel='rbf', max_iter=-1, nu=0.5, probability=True, random_state=None,\n",
      "      shrinking=True, tol=0.001, verbose=False) -----\n",
      "-----Starting LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -----\n",
      "-----Starting DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') -----\n",
      "-----Starting ExtraTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                    max_features='auto', max_leaf_nodes=None,\n",
      "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                    min_samples_leaf=1, min_samples_split=2,\n",
      "                    min_weight_fraction_leaf=0.0, random_state=None,\n",
      "                    splitter='random') -----\n",
      "-----Starting LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=False, tol=0.0001) -----\n",
      "-----Starting QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "                              store_covariance=False, tol=0.0001) -----\n"
     ]
    }
   ],
   "source": [
    "# Creating a df to compare various attributes of an algorithm\n",
    "compare_col = ['Name', 'Parameters', 'Train Accuracy', 'Test Accuracy', 'Time']\n",
    "compare = pd.DataFrame(columns = compare_col)\n",
    "row = 0\n",
    "for alg in MLA:\n",
    "    print('-----Starting %s -----' %str(alg))\n",
    "    time0 = time.time()\n",
    "    score = cross_val_score(alg, x_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "    compare.loc[row, 'Name'] = alg.__class__.__name__\n",
    "    compare.loc[row, 'Parameters'] = str(alg.get_params())\n",
    "    compare.loc[row, 'Train Accuracy'] = score.mean()\n",
    "    model = alg.fit(x_train, y_train)\n",
    "    train_predict = model.predict(x_test)\n",
    "#     y_sub = model.predict(submission)\n",
    "    compare.loc[row, 'Test Accuracy'] = accuracy_score(y_test, train_predict)\n",
    "    compare.loc[row, 'Time'] = time.time() - time0\n",
    "    row+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.793387</td>\n",
       "      <td>0.847534</td>\n",
       "      <td>0.414732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.790469</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.218361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>0.811659</td>\n",
       "      <td>1.17721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': 'warn',...</td>\n",
       "      <td>0.800714</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>6.23229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.77369</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.067343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.790491</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>1.11004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.802208</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.094867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
       "      <td>0.799245</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.0996759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.71686</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.0536001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.766274</td>\n",
       "      <td>0.7713</td>\n",
       "      <td>0.055371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.724681</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.0647509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.772424</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.247889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.748879</td>\n",
       "      <td>0.362293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.618231</td>\n",
       "      <td>0.67713</td>\n",
       "      <td>0.0858848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.546345</td>\n",
       "      <td>0.636771</td>\n",
       "      <td>0.060307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'class_weight': ...</td>\n",
       "      <td>0.588289</td>\n",
       "      <td>0.61435</td>\n",
       "      <td>1.23147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.570355</td>\n",
       "      <td>0.605381</td>\n",
       "      <td>2.57891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'cache_size': 200, 'class_weight': None, 'coe...</td>\n",
       "      <td>0.573317</td>\n",
       "      <td>0.578475</td>\n",
       "      <td>1.14692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.58101</td>\n",
       "      <td>0.403587</td>\n",
       "      <td>0.102074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.636165</td>\n",
       "      <td>0.399103</td>\n",
       "      <td>0.0571043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.528091</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.130621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "1               BaggingClassifier   \n",
       "4          RandomForestClassifier   \n",
       "3      GradientBoostingClassifier   \n",
       "6            LogisticRegressionCV   \n",
       "12                     GaussianNB   \n",
       "0              AdaBoostClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "18            ExtraTreeClassifier   \n",
       "11                    BernoulliNB   \n",
       "17         DecisionTreeClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "16                      LinearSVC   \n",
       "13           KNeighborsClassifier   \n",
       "7     PassiveAggressiveClassifier   \n",
       "14                            SVC   \n",
       "5       GaussianProcessClassifier   \n",
       "15                          NuSVC   \n",
       "9                   SGDClassifier   \n",
       "10                     Perceptron   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                           Parameters Train Accuracy  \\\n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...       0.793387   \n",
       "4   {'bootstrap': True, 'class_weight': None, 'cri...       0.790469   \n",
       "3   {'criterion': 'friedman_mse', 'init': None, 'l...       0.817315   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': 'warn',...       0.800714   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}        0.77369   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...       0.790491   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...       0.802208   \n",
       "19  {'n_components': None, 'priors': None, 'shrink...       0.799245   \n",
       "18  {'class_weight': None, 'criterion': 'gini', 'm...        0.71686   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...       0.766274   \n",
       "17  {'class_weight': None, 'criterion': 'gini', 'm...       0.724681   \n",
       "2   {'bootstrap': False, 'class_weight': None, 'cr...       0.772424   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...       0.746867   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...       0.618231   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...       0.546345   \n",
       "14  {'C': 1.0, 'cache_size': 200, 'class_weight': ...       0.588289   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...       0.570355   \n",
       "15  {'cache_size': 200, 'class_weight': None, 'coe...       0.573317   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...        0.58101   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...       0.636165   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...       0.528091   \n",
       "\n",
       "   Test Accuracy       Time  \n",
       "1       0.847534   0.414732  \n",
       "4       0.820628   0.218361  \n",
       "3       0.811659    1.17721  \n",
       "6       0.807175    6.23229  \n",
       "12      0.793722   0.067343  \n",
       "0       0.784753    1.11004  \n",
       "8       0.775785   0.094867  \n",
       "19      0.775785  0.0996759  \n",
       "18      0.775785  0.0536001  \n",
       "11        0.7713   0.055371  \n",
       "17      0.762332  0.0647509  \n",
       "2       0.757848   0.247889  \n",
       "16      0.748879   0.362293  \n",
       "13       0.67713  0.0858848  \n",
       "7       0.636771   0.060307  \n",
       "14       0.61435    1.23147  \n",
       "5       0.605381    2.57891  \n",
       "15      0.578475    1.14692  \n",
       "9       0.403587   0.102074  \n",
       "10      0.399103  0.0571043  \n",
       "20      0.376682   0.130621  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top performers\n",
    "compare.sort_values(by=['Test Accuracy', 'Train Accuracy'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting the Confucian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 384)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 703)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "413    False\n",
       "414    False\n",
       "415    False\n",
       "416    False\n",
       "417    False\n",
       "Name: Fare, Length: 418, dtype: bool"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
